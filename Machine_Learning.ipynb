{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Pnf5X5hyB2Ac-iIfdbpNclT2kYKJV_Ah",
      "authorship_tag": "ABX9TyNL8tTEzi1WD3Sn37X3rCPc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmetnihat/ses_analizi/blob/main/Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhWlTxla6Qvy"
      },
      "source": [
        "#importlar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjB8m4GsHxVY"
      },
      "source": [
        "!pip install joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import seaborn as sbn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn import datasets, svm, metrics \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score,recall_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "import sklearn.feature_selection\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import joblib\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIUlGp_T6TZR"
      },
      "source": [
        "#csv okuma ve işlemler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyU5ayp0ktvE"
      },
      "source": [
        "dataFrame = pd.read_csv('/content/drive/MyDrive/csvler/kedi_kopek_insankonusma_insanciglik.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrkcmRjvfHa6"
      },
      "source": [
        "dataFrame = pd.read_csv('/content/drive/MyDrive/csvler/librosasonmfcc40/librosa40nitelik.csv')\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0\", axis=1)\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0.1\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKXzmTMfVY-Y"
      },
      "source": [
        "dataFrame = pd.read_csv('/content/drive/MyDrive/csvler/librosasonmfcc40/librosa40nitelikhuman200.csv')\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0\", axis=1)\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0.1\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOeTB59ZwNrx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gr0b1l21aH1"
      },
      "source": [
        "dataFrame= pd.read_csv('/content/drive/MyDrive/csvler/librosa3nitelik.csv')\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0\", axis=1)\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0.1\", axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGCu3ibjVW8F"
      },
      "source": [
        "dataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmjO2XkPlHVc"
      },
      "source": [
        "myset = set(dataFrame[\"Duygu\"])\n",
        "print(myset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UUayg9AwPk4"
      },
      "source": [
        "dataFrame = pd.read_csv('/content/drive/MyDrive/csvler/librosasonmfcc127/librosa40nitelikhuman200.csv')\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0\", axis=1)\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0.1\", axis=1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"human2\",value =1)\n",
        "#dataFrame= dataFrame.replace(to_replace =\"human\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"oksurme\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"nefes\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"ciglik\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"dogs\",value =5)\n",
        "dataFrame= dataFrame.replace(to_replace =\"cats\",value =5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lSKL2aXSNOq"
      },
      "source": [
        "dataFrame = pd.read_csv('/content/drive/MyDrive/csvler/librosasonmfcc127/hayvansinifi.csv')\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0\", axis=1)\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0.1\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3O9EQuJfHSB"
      },
      "source": [
        "dataFrame = pd.read_csv('/content/drive/MyDrive/csvler/librosasonmfcc127/insansinifi.csv')\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0\", axis=1)\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0.1\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm8a2juZTpEZ"
      },
      "source": [
        "## isimlendirme değiştir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zfXB2H_sJTx"
      },
      "source": [
        "dataFrame= dataFrame.replace(to_replace =\"kedi\",value =\"kedi_kopek\")\n",
        "dataFrame= dataFrame.replace(to_replace =\"kopek\",value =\"kedi_kopek\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykhVr6K6FYR5"
      },
      "source": [
        "#sayisala çevir \n",
        "dataFrame= dataFrame.replace(to_replace =\"kedi\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"kopek\",value =2)\n",
        "dataFrame= dataFrame.replace(to_replace =\"insanciglik\",value =3)\n",
        "dataFrame= dataFrame.replace(to_replace =\"insankonusma\",value =4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbLwocGESwYv"
      },
      "source": [
        "dataFrame= dataFrame.replace(to_replace =\"human2\",value =1)\n",
        "#dataFrame= dataFrame.replace(to_replace =\"human\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"oksurme\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"nefes\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"ciglik\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"dogs\",value =5)\n",
        "dataFrame= dataFrame.replace(to_replace =\"cats\",value =5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2rjCkZSwoAW"
      },
      "source": [
        "dataFrame= dataFrame.replace(to_replace =\"human2\",value =1)\n",
        "#dataFrame= dataFrame.replace(to_replace =\"human\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"oksurme\",value =2)\n",
        "dataFrame= dataFrame.replace(to_replace =\"nefes\",value =3)\n",
        "dataFrame= dataFrame.replace(to_replace =\"ciglik\",value =4)\n",
        "dataFrame= dataFrame.replace(to_replace =\"dogs\",value =5)\n",
        "dataFrame= dataFrame.replace(to_replace =\"cats\",value =5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F718FX_5Tsf5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN_FORvz7FdB"
      },
      "source": [
        "#sayisala çevir \n",
        "dataFrame= dataFrame.replace(to_replace =\"cats\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"dogs\",value =2)\n",
        "dataFrame= dataFrame.replace(to_replace =\"human\",value =3)\n",
        "#dataFrame= dataFrame.replace(to_replace =\"insankonusma\",value =4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKlXpJs3T5II"
      },
      "source": [
        "## Dropla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9_CEIn2li3s"
      },
      "source": [
        "dataFrame = dataFrame.drop(\"file\",axis=1)\n",
        "dataFrame = dataFrame.drop(\"start\",axis=1)\n",
        "dataFrame = dataFrame.drop(\"end\",axis=1)\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH4fMYCa1m6W"
      },
      "source": [
        "dataFrame = dataFrame.drop(\"Unnamed: 0.1\", axis=1)\n",
        "dataFrame = dataFrame.drop(\"Unnamed: 0\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2qIDNdhTvYx"
      },
      "source": [
        "## Open smile için öznitelik isimlerine göre seç"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRnWcUfvO8K2"
      },
      "source": [
        "audspec = dataFrame.keys()\n",
        "veriler = [\"Duygu\"]\n",
        "for i in range(0,6378):\n",
        "  #  if \"zcr\" in audspec[i] or  \"mfcc\" in audspec[i]:\n",
        "\n",
        "  if \"mfcc\" in audspec[i]:\n",
        "    print(audspec[i])\n",
        "    veriler.append(audspec[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6BLYGHaPdmU"
      },
      "source": [
        "  dataFrame = dataFrame.loc[:,veriler]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yNcAcGWmcwf"
      },
      "source": [
        "#librosa selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EETtpN2bmmdr"
      },
      "source": [
        "dectree = [\"Duygu\",\"0\", \"1\", \"2\", \"3\", \"4\", \"6\", \"7\", \"8\", \"9\", \"15\", \"16\", \"17\", \"18\", \"21\", \"23\", \"24\", \"34\", \"40\", \"47\", \"53\", \"57\", \"62\", \"65\", \"66\", \"72\", \"73\", \"80\", \"83\", \"84\", \"90\", \"94\", \"96\", \"99\", \"101\", \"104\", \"105\", \"112\", \"115\", \"121\", \"123\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op1DjFVmLxCe"
      },
      "source": [
        "svmss = ['Duygu','0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '21', '22', '24', '25', '27', '29', '30', '31', '32', '33', '35', '36', '37']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEKZYWcimvf8"
      },
      "source": [
        "dataFrame = dataFrame.loc[:,svmss]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgCmj2_Zm6su"
      },
      "source": [
        "dataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVmi6xcicxyS"
      },
      "source": [
        "dectree = [\"Duygu\",\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"28\", \"29\", \"30\", \"31\", \"32\", \"33\", \"34\", \"36\", \"37\", \"39\", \"40\", \"41\", \"42\", \"43\", \"45\", \"46\", \"47\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"58\", \"59\", \"62\", \"63\", \"64\", \"65\", \"66\", \"67\", \"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\", \"77\", \"78\", \"79\", \"80\", \"81\", \"82\", \"83\", \"84\", \"86\", \"88\", \"89\", \"90\", \"91\", \"92\", \"93\", \"94\", \"98\", \"100\", \"102\", \"103\", \"105\", \"107\", \"108\", \"109\", \"110\", \"111\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\", \"121\", \"123\", \"124\", \"127\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o2aByCOLwjH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRHYT8APTP8R"
      },
      "source": [
        "#Ayırmalar Random State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNKQ-ey1lqoU"
      },
      "source": [
        "y = dataFrame[\"Duygu\"].values\n",
        "X = dataFrame.drop(\"Duygu\",axis = 1).values\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=15)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQlFVtMUJF4m"
      },
      "source": [
        "#PCA (Bu düzlemi çeviriyor bir şeyler yapıyor kafasınna göre )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of4FkkbqJHtt"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x_train = pca.fit_transform(x_train)\n",
        "x_test = pca.transform(x_test)\n",
        "\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL_1ESGvLNSy"
      },
      "source": [
        "#tek kod modeller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imcuWP8mK320"
      },
      "source": [
        "print(\"---------------------------DecisionTreeRegressor ------------------------------------\")\n",
        "\n",
        "model = DecisionTreeRegressor().fit(x_train,y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/model_decisionregress.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')\n",
        "print(\"---------------------------DecisionTreeClassifier ------------------------------------\")\n",
        "\n",
        "model = DecisionTreeClassifier().fit(x_train,y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/model_decisiontree.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')\n",
        "print(\"---------------------------GaussianNB ------------------------------------\")\n",
        "\n",
        "model = GaussianNB().fit(x_train, y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "#joblib.dump(model, f'/content/drive/MyDrive/gausss.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')\n",
        "print(\"---------------------------Logistic Regression ------------------------------------\")\n",
        "model = LogisticRegression(solver='liblinear', random_state=15).fit(x_train, y_train)\n",
        "import joblib\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "guven = model.predict_proba(x_test)\n",
        "print(guven)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/model_logisticreg.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')\n",
        "print(\"--------------------------- Linear SVC ------------------------------------\")\n",
        "\n",
        "model= svm.SVC(kernel='linear',probability=True,gamma='auto').fit(x_train,y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/svmlineer.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')\n",
        "print(\"--------------------------- rbf SVC ------------------------------------\")\n",
        "\n",
        "model= svm.SVC(kernel='rbf',probability=True,gamma='auto').fit(x_train,y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/model_rbf.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')\n",
        "print(\"--------------------------- KNN n=3 ------------------------------------\")\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree').fit(x_train,y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/knn.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8H8s4xtYB5K"
      },
      "source": [
        "print(\"--------------------------- xgboost ------------------------------------\")\n",
        "\n",
        "import xgboost as xgb\n",
        "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
        "dtest = xgb.DMatrix(x_test, label=y_test)\n",
        "\n",
        "# xgboost parametreleri\n",
        "params = {\n",
        "    'max_depth': 2,\n",
        "    'eta': 0.4,\n",
        "    'silent': 1,\n",
        "    'object': 'multi:softmax',\n",
        "    'num_class': 3\n",
        "}\n",
        "# egit\n",
        "model = xgb.XGBClassifier(**params)\n",
        "model.fit(x_train,y_train)\n",
        "# test et\n",
        "preds = model.predict(x_test)\n",
        "print(preds)\n",
        "labels = dtest.get_label()\n",
        "print(preds) # testx icin tahminler\n",
        "print(labels) # olmasi gerekenler\n",
        "\n",
        "# sklearn performans olcutleri\n",
        "from sklearn.metrics import precision_score, accuracy_score\n",
        "# Keskinlik ve dogruluk\n",
        "print(f1_score(y_test, preds, average='macro'))\n",
        "print(accuracy_score(y_test,preds))\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import pickle\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "model.save_model('model_file_name.json')\n",
        "\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PHashkI6XrZ"
      },
      "source": [
        "#modeller"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyIgEVDXR-4K"
      },
      "source": [
        "## KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMvTp7Amo_8g"
      },
      "source": [
        "print(\"--------------------------- KNN n=3 ------------------------------------\")\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree').fit(x_train,y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/knn.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBkmd-0JS-ib"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "n_classes = 5\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "# classifier\n",
        "y_train = label_binarize(y_train, classes=[0,1,2,3,4])\n",
        "y_test = label_binarize(y_test, classes=[0,1,2,3,4])\n",
        "#clf = OneVsRestClassifier(LinearSVC(random_state=0)).fit(x_train, y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "#lineer için y score\n",
        "  #y_score = model.decision_function(x_test)\n",
        "#knn için y score\n",
        "y_score = model.predict_proba(x_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    \n",
        "    plt.title(f'Receiver operating characteristic example -{i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves bu değil\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "        label='macro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, \n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
        "plt.show()\n",
        "# plt.savefig('rocauclineer.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmg5moyPSFix"
      },
      "source": [
        "## DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q86zLQFbpBDB"
      },
      "source": [
        "print(\"---------------------------DecisionTreeClassifier ------------------------------------\")\n",
        "\n",
        "model = DecisionTreeClassifier().fit(x_train,y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/model_decisiontree.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaBrYDFlS_Ui"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "n_classes = 3\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "# classifier\n",
        "y_train = label_binarize(y_train, classes=[0,1,2])\n",
        "y_test = label_binarize(y_test, classes=[0,1,2])\n",
        "#clf = OneVsRestClassifier(LinearSVC(random_state=0)).fit(x_train, y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "#lineer için y score\n",
        "  #y_score = model.decision_function(x_test)\n",
        "#knn için y score\n",
        "y_score = model.predict_proba(x_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    \n",
        "    plt.title(f'Receiver operating characteristic example -{i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves bu değil\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "        label='macro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, \n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
        "plt.show()\n",
        "# plt.savefig('rocauclineer.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9-jSMXtSFqC"
      },
      "source": [
        "## GaussianNB\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0seQ3JtjpA_4"
      },
      "source": [
        "print(\"---------------------------GaussianNB ------------------------------------\")\n",
        "\n",
        "model = GaussianNB().fit(x_train, y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "#joblib.dump(model, f'/content/drive/MyDrive/gausss.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDJcetVlS_25"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "n_classes = 3\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "# classifier\n",
        "y_train = label_binarize(y_train, classes=[0,1,2])\n",
        "y_test = label_binarize(y_test, classes=[0,1,2])\n",
        "#clf = OneVsRestClassifier(LinearSVC(random_state=0)).fit(x_train, y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "#lineer için y score\n",
        "  #y_score = model.decision_function(x_test)\n",
        "#knn için y score\n",
        "y_score = model.predict_proba(x_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    \n",
        "    plt.title(f'Receiver operating characteristic example -{i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves bu değil\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "        label='macro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, \n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
        "plt.show()\n",
        "# plt.savefig('rocauclineer.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga0fCaOqSFuQ"
      },
      "source": [
        "## Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdYWEzripA6Q"
      },
      "source": [
        "print(\"---------------------------Logistic Regression ------------------------------------\")\n",
        "model = LogisticRegression(solver='liblinear', random_state=15).fit(x_train, y_train)\n",
        "import joblib\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "guven = model.predict_proba(x_test)\n",
        "print(guven)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "#joblib.dump(model, f'/content/drive/MyDrive/model_logisticreg.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWtCf-aqXxpl"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPls5-iWTAUK"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "n_classes = 5\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "# classifier\n",
        "y_train = label_binarize(y_train, classes=[1,2,3,4,5])\n",
        "y_test = label_binarize(y_test, classes=[1,2,3,4,5])\n",
        "#clf = OneVsRestClassifier(LinearSVC(random_state=0)).fit(x_train, y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "#lineer için y score\n",
        "  #y_score = model.decision_function(x_test)\n",
        "#knn için y score\n",
        "y_score = model.predict_proba(x_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    \n",
        "    plt.title(f'Receiver operating characteristic example -{i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves bu değil\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "        label='macro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, \n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
        "plt.show()\n",
        "# plt.savefig('rocauclineer.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6qnkAU_Sku-"
      },
      "source": [
        "## Linear SVC\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5eBvVRkpAm4"
      },
      "source": [
        "print(\"--------------------------- Linear SVC ------------------------------------\")\n",
        "\n",
        "model= svm.SVC(kernel='linear',probability=True,gamma='auto').fit(x_train,y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/svmlineer.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk_IQ1VnTA3q"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "n_classes = 5\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "# classifier\n",
        "y_train = label_binarize(y_train, classes=[1,2,3,4,5])\n",
        "y_test = label_binarize(y_test, classes=[1,2,3,4,5])\n",
        "#clf = OneVsRestClassifier(LinearSVC(random_state=0)).fit(x_train, y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "#lineer için y score\n",
        "  #y_score = model.decision_function(x_test)\n",
        "#knn için y score\n",
        "y_score = model.predict_proba(x_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    \n",
        "    plt.title(f'Receiver operating characteristic example -{i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves bu değil\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "        label='macro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, \n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
        "plt.show()\n",
        "# plt.savefig('rocauclineer.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgNlifPeSZdR"
      },
      "source": [
        "## rbf SVC\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcsZ19QpASI"
      },
      "source": [
        "print(\"--------------------------- rbf SVC ------------------------------------\")\n",
        "\n",
        "model= svm.SVC(kernel='rbf',probability=True,gamma='auto').fit(x_train,y_train)\n",
        "\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/model_rbf.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOneGnEeTBTa"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "n_classes = 5\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "# classifier\n",
        "y_train = label_binarize(y_train, classes=[1,2,3,4,5])\n",
        "y_test = label_binarize(y_test, classes=[1,2,3,4,5])\n",
        "#clf = OneVsRestClassifier(LinearSVC(random_state=0)).fit(x_train, y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "#lineer için y score\n",
        "  #y_score = model.decision_function(x_test)\n",
        "#knn için y score\n",
        "y_score = model.predict_proba(x_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    \n",
        "    plt.title(f'Receiver operating characteristic example -{i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves bu değil\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "        label='macro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, \n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
        "plt.show()\n",
        "# plt.savefig('rocauclineer.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcV1itFYSFxS"
      },
      "source": [
        "## Decision Tree Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yheZzg_mlv6k"
      },
      "source": [
        "print(\"---------------------------DecisionTreeRegressor ------------------------------------\")\n",
        "\n",
        "model = DecisionTreeRegressor().fit(x_train,y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "joblib.dump(model, f'/content/drive/MyDrive/model_decisionregress.pkl')\n",
        "scores = cross_val_score(model, x_test, y_test)\n",
        "print(\"Validation Score Mean\")\n",
        "print(scores.mean())\n",
        "print(\"Validation Sonuçları\")\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnFCAfpxTB3B"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "n_classes = 3\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "# classifier\n",
        "y_train = label_binarize(y_train, classes=[0,1,2])\n",
        "y_test = label_binarize(y_test, classes=[0,1,2])\n",
        "#clf = OneVsRestClassifier(LinearSVC(random_state=0)).fit(x_train, y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "#lineer için y score\n",
        "  #y_score = model.decision_function(x_test)\n",
        "#knn için y score\n",
        "y_score = model.predict_proba(x_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    \n",
        "    plt.title(f'Receiver operating characteristic example -{i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves bu değil\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "        label='macro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, \n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
        "plt.show()\n",
        "# plt.savefig('rocauclineer.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnG4uKWaGWOh"
      },
      "source": [
        "##dec tree feature importante\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRniI6BNdgV4"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "# define the model\n",
        "model = DecisionTreeRegressor().fit(x_train,y_train)\n",
        "# fit the model\n",
        "# get importance\n",
        "importance = model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "  if v > 0.01:\n",
        "    #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "    print(i)\n",
        "\n",
        "# plot feature importance\n",
        "    \n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.rcParams[\"figure.figsize\"] = (30,25)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERxNW2ZIFSEC"
      },
      "source": [
        "#XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "398co_MCGKMZ"
      },
      "source": [
        "print(\"--------------------------- xgboost ------------------------------------\")\n",
        "\n",
        "import xgboost as xgb\n",
        "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
        "dtest = xgb.DMatrix(x_test, label=y_test)\n",
        "\n",
        "# xgboost parametreleri\n",
        "params = {\n",
        "    'max_depth': 2,\n",
        "    'eta': 0.4,\n",
        "    'silent': 1,\n",
        "    'object': 'multi:softmax',\n",
        "    'num_class': 3\n",
        "}\n",
        "# egit\n",
        "model = xgb.XGBClassifier(**params)\n",
        "model.fit(x_train,y_train)\n",
        "# test et\n",
        "preds = model.predict(x_test)\n",
        "print(preds)\n",
        "labels = dtest.get_label()\n",
        "print(preds) # testx icin tahminler\n",
        "print(labels) # olmasi gerekenler\n",
        "\n",
        "# sklearn performans olcutleri\n",
        "from sklearn.metrics import precision_score, accuracy_score\n",
        "# Keskinlik ve dogruluk\n",
        "print(f1_score(y_test, preds, average='macro'))\n",
        "print(accuracy_score(y_test,preds))\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import pickle\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "print(classification_report(y_test,tahminlerimiz2))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test,tahminlerimiz2))\n",
        "print(\"Accuracy Score\")\n",
        "print(accuracy_score(y_test,tahminlerimiz2))\n",
        "model.save_model('model_file_name.json')\n",
        "\n",
        "print(scores)\n",
        "cm = confusion_matrix(y_test, tahminlerimiz2,  normalize = 'true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpqE0fcJW6Zt"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=233, n_features=6373, n_informative=5, random_state=1)\n",
        "# define the model\n",
        "model = DecisionTreeRegressor()\n",
        "# fit the model\n",
        "model.fit(X, y)\n",
        "# get importance\n",
        "importance = model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "  if v > 0.01:\n",
        "    #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "    print(i)\n",
        "\n",
        "# plot feature importance\n",
        "    \n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.rcParams[\"figure.figsize\"] = (30,25)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiXsAFrHJ1Xb"
      },
      "source": [
        "#Roc Auc\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2stL5K8KOm5-"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "n_classes = 3\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "# classifier\n",
        "y_train = label_binarize(y_train, classes=[0,1,2])\n",
        "y_test = label_binarize(y_test, classes=[0,1,2])\n",
        "#clf = OneVsRestClassifier(LinearSVC(random_state=0)).fit(x_train, y_train)\n",
        "tahminlerimiz2 = model.predict(x_test)\n",
        "#lineer için y score\n",
        "  #y_score = model.decision_function(x_test)\n",
        "#knn için y score\n",
        "y_score = model.predict_proba(x_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "# Plot of a ROC curve for a specific class\n",
        "for i in range(n_classes):\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    \n",
        "    plt.title(f'Receiver operating characteristic example -{i}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves bu değil\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "        label='macro-average ROC curve (area = {0:0.2f})'\n",
        "              ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, \n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
        "plt.show()\n",
        "# plt.savefig('rocauclineer.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuIgdbmd6dry"
      },
      "source": [
        "#feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIQxxhycTbr5"
      },
      "source": [
        "#### SFS BFS (Bunlar çok sağlam öznitelik seçimleri ama mallayabiliyorlar ya da makineyi mallatıyorlar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r_A-XOk2rvr"
      },
      "source": [
        "dataFrame.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDir5VQZJE-8"
      },
      "source": [
        "import mlxtend\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqFzms31KBhu"
      },
      "source": [
        "sfs1 = SFS(model, forward=False, verbose=2, scoring='accuracy', cv=0, n_jobs=-1, k_features=1).fit(x_train,y_train)\n",
        "print(sfs1)\n",
        "fig1 = plot_sfs(sfs1.get_metric_dict(), kind='std_dev')\n",
        "result_LR = pd.DataFrame.from_dict(sfs1.get_metric_dict(confidence_interval=0.90)).T\n",
        "result_LR.sort_values('avg_score', ascending=0, inplace=True)\n",
        "result_LR.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sR-RS0REDhn"
      },
      "source": [
        "result_LR.to_excel(\"a.xlsx\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9LuWzmoKCYa"
      },
      "source": [
        "fig2 = plot_sfs(sfs1.get_metric_dict(), kind='std_dev')\n",
        "result_LR = pd.DataFrame.from_dict(sfs1.get_metric_dict(confidence_interval=0.90)).T\n",
        "result_LR.sort_values('avg_score', ascending=0, inplace=True)\n",
        "result_LR.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K-vT9VQLMb3"
      },
      "source": [
        "result_LR.to_excel(\"sfs.xlsx\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkICnfKZKDai"
      },
      "source": [
        "from sklearn.externals import joblib \n",
        "joblib.dump(sfs1, f'/content/drive/MyDrive/sfs100.pkl')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbUpMM2WKEq7"
      },
      "source": [
        "sfs1.k_feature_idx_[40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA1w3VGFKHFL"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FvfKH9GKIca"
      },
      "source": [
        "fig1.set_size_inches(30, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaPylTQeGbh8"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "# define the model\n",
        "model = DecisionTreeRegressor()\n",
        "# fit the model\n",
        "model.fit(x_train,y_train)\n",
        "# get importance\n",
        "importance = model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "  if v > 0.01:\n",
        "    #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "    print(i)\n",
        "\n",
        "# plot feature importance\n",
        "    \n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.rcParams[\"figure.figsize\"] = (30,25)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGJ0KZ5kRn1V"
      },
      "source": [
        "dataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcKwOjy1kqR9"
      },
      "source": [
        "##  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jogmvhdf6m3R"
      },
      "source": [
        "#Masaüstü test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzQEj9Gf63AR"
      },
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goQJJTUJ6rZB"
      },
      "source": [
        "!pip install pyaudio\n",
        "!pip install opensmile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Owpmn-H6pIj"
      },
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import seaborn as sbn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn import datasets, svm, metrics \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score,recall_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "import sklearn.feature_selection\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import opensmile\n",
        "CHUNK = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 2\n",
        "RATE = 44100\n",
        "RECORD_SECONDS = 3\n",
        "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
        "\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                frames_per_buffer=CHUNK)\n",
        "\n",
        "print(\"* recording\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "    data = stream.read(CHUNK)\n",
        "    frames.append(data)\n",
        "\n",
        "print(\"* done recording\")\n",
        "\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate()\n",
        "\n",
        "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
        "wf.setnchannels(CHANNELS)\n",
        "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
        "wf.setframerate(RATE)\n",
        "wf.writeframes(b''.join(frames))\n",
        "wf.close()\n",
        "smile = opensmile.Smile(\n",
        "      feature_set=opensmile.FeatureSet.ComParE_2016,\n",
        "      feature_level=opensmile.FeatureLevel.Functionals,\n",
        "  )\n",
        "y = smile.process_file('output.wav')\n",
        "y.to_csv(\"ses.csv\")\n",
        "dataFrame = pd.read_csv(\"ses.csv\")\n",
        "dataFrame = dataFrame.drop(\"file\",axis=1)\n",
        "dataFrame = dataFrame.drop(\"start\",axis=1)\n",
        "dataFrame = dataFrame.drop(\"end\",axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dataFrame)\n",
        "dataFrame = scaler.transform(dataFrame)\n",
        "model = joblib.load('model_decisiontree.pkl')\n",
        "\n",
        "tahmin = model.predict(dataFrame)\n",
        "guven = model.predict_proba(dataFrame)\n",
        "print(guven)\n",
        "print(tahmin)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTlvIyPA7uUA"
      },
      "source": [
        "!apt-get install libsox-fmt-all libsox-dev sox > /dev/null\n",
        "! python -m pip install torchaudio > /dev/null\n",
        "! python -m pip install git+https://github.com/facebookresearch/WavAugment.git > /dev/null\n",
        "!pip install ffmpeg-python > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ23pTd98Udg"
      },
      "source": [
        "import torchaudio\n",
        "# Download example from WavAugment\n",
        "! wget https://raw.githubusercontent.com/facebookresearch/WavAugment/master/tests/test.wav > /dev/null\n",
        "\n",
        "# and load it as a tensor\n",
        "x, sr = torchaudio.load('test.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYlahh968F-g"
      },
      "source": [
        "# code taken from https://ricardodeazambuja.com/deep_learning/2019/03/09/audio_and_video_google_colab/\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "import ffmpeg\n",
        "import tempfile\n",
        "import pathlib\n",
        "\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "    path = pathlib.Path(tmpdirname) / 'test.wav'\n",
        "    with open(path, 'wb') as f:\n",
        "       f.write(riff)\n",
        "       \n",
        "    x, sr = torchaudio.load(path)\n",
        "\n",
        "  return x, sr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4MfuXdzBU9l"
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leIPT_JMBN4W"
      },
      "source": [
        "from pydub import AudioSegment\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8DfW8x5KtXA"
      },
      "source": [
        "smile = opensmile.Smile(\n",
        "      feature_set=opensmile.FeatureSet.ComParE_2016,\n",
        "      feature_level=opensmile.FeatureLevel.Functionals,\n",
        "  )\n",
        "y = smile.process_file('test.wav')\n",
        "y.to_csv(\"ses.csv\")\n",
        "ses = pd.read_csv(\"ses.csv\")\n",
        "ses = ses.drop(\"file\",axis=1)\n",
        "ses = ses.drop(\"start\",axis=1)\n",
        "ses = ses.drop(\"end\",axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(ses)\n",
        "ses = scaler.transform(ses)\n",
        "ses.to_csv(\"ses.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jaxKlOq8KT4"
      },
      "source": [
        "x, sr = get_audio()\n",
        "x.export(f\"set.wav\", format=\"wav\")\n",
        "smile = opensmile.Smile(\n",
        "      feature_set=opensmile.FeatureSet.ComParE_2016,\n",
        "      feature_level=opensmile.FeatureLevel.Functionals,\n",
        "  )\n",
        "y = smile.process_file('set.wav')\n",
        "y.to_csv(\"ses.csv\")\n",
        "ses = pd.read_csv(\"ses.csv\")\n",
        "ses = ses.drop(\"file\",axis=1)\n",
        "ses = ses.drop(\"start\",axis=1)\n",
        "ses = ses.drop(\"end\",axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(ses)\n",
        "ses = scaler.transform(ses)\n",
        "model = joblib.load('/content/drive/MyDrive/model_logisticreg.pkl')\n",
        "\n",
        "tahmin = model.predict(ses)\n",
        "guven = model.predict_proba(ses)\n",
        "print(guven)\n",
        "print(tahmin)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFrHHDi4CUkU"
      },
      "source": [
        "audio.export(f\"set.wav\", format=\"wav\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EgHW7NOrYDB"
      },
      "source": [
        "# Deneme yapmak için öncelikle ses kaydedicinizden kayıt alın. Sonra sisteme yükleyeyin. m4a formatındaki ses kaydını wav'a çevirin ve kodu çalıştırın."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Um0o6HrcAM"
      },
      "source": [
        "!pip install ffmpeg-python\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ttYyK3purOh"
      },
      "source": [
        "!ffmpeg -i /content/drive/MyDrive/sesler/notrerdem.m4a audio.wav #m4a dosyasını wava çevirme\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtBOJMBVsw4z"
      },
      "source": [
        "!pip install opensmile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iKJ4_82-Zne"
      },
      "source": [
        "!pip install librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK0S3XeRsflc"
      },
      "source": [
        "import joblib\n",
        "import librosa\n",
        "smile = opensmile.Smile(\n",
        "      feature_set=opensmile.FeatureSet.ComParE_2016,\n",
        "      feature_level=opensmile.FeatureLevel.Functionals,\n",
        "  )\n",
        "y = smile.process_file('audio.wav')\n",
        "y.to_csv(\"ses.csv\")\n",
        "Deneme = pd.read_csv(\"ses.csv\")\n",
        "print(Deneme)\n",
        "audspec = Deneme.keys()\n",
        "veriler = []\n",
        "for i in range(0,6376):\n",
        "  if  \"mfcc\" in audspec[i]:\n",
        "    print(audspec[i])\n",
        "    veriler.append(audspec[i])\n",
        "Deneme = Deneme.loc[:,veriler]\n",
        "Deneme2 = Deneme.loc[:,veriler]\n",
        "\n",
        "print(Deneme)\n",
        "Deneme=Deneme.values\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(Deneme)\n",
        "x_deneme = scaler.transform(Deneme)\n",
        "\n",
        "#model = pickle.load(open('xgboost1.pkl', \"rb\"))\n",
        "\n",
        "model = joblib.load('/content/drive/MyDrive/model_decisiontree.pkl')\n",
        "\n",
        "tahmin = model.predict(x_deneme)\n",
        "guven = model.predict_proba(x_deneme)\n",
        "print(guven)\n",
        "print(tahmin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOoBYTpbQLzq"
      },
      "source": [
        "dectree = [\"Duygu\",\"0\", \"1\", \"2\", \"3\", \"4\", \"6\", \"7\", \"8\", \"9\", \"15\", \"16\", \"17\", \"18\", \"21\", \"23\", \"24\", \"34\", \"40\", \"47\", \"53\", \"57\", \"62\", \"65\", \"66\", \"72\", \"73\", \"80\", \"83\", \"84\", \"90\", \"94\", \"96\", \"99\", \"101\", \"104\", \"105\", \"112\", \"115\", \"121\", \"123\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBXIO9goQLzx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4_IqjPO-nhy"
      },
      "source": [
        "import joblib\n",
        "import librosa\n",
        "import os\n",
        "dosyas = os.scandir('/content/drive/MyDrive/Dataguncel/cats/')\n",
        "for i in dosyas:\n",
        "  dosya_isim = i.name\n",
        "\n",
        "  x,sr = librosa.load('/content/drive/MyDrive/Dataguncel/cats/' + dosya_isim)\n",
        " \n",
        "  mfccs=librosa.feature.mfcc(y=x, sr=sr, n_mfcc=40)\n",
        "  mfccs_processed = np.mean(mfccs.T,axis=0)\n",
        "  result = np.array(mfccs_processed)\n",
        "  mfkkk = pd.DataFrame(result)\n",
        "  mfkkk = mfkkk.transpose()\n",
        "\n",
        "  x_deneme = scaler.transform(mfkkk)\n",
        "  #model = pickle.load(open('xgboost1.pkl', \"rb\"))\n",
        "\n",
        "  model = joblib.load('/content/drive/MyDrive/knn.pkl')\n",
        "\n",
        "  tahmin = model.predict(x_deneme)\n",
        "  guven = model.predict_proba(x_deneme)\n",
        "  array = np.append(array,tahmin)\n",
        "  print(array)\n",
        "  print(\"----\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlWVHmT4sIvb"
      },
      "source": [
        "array.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MExtXmKGrzVn"
      },
      "source": [
        "np.unique(array, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vKTs__LsLXz"
      },
      "source": [
        "(254/277)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iINkX4dk_oz5"
      },
      "source": [
        "!ffmpeg -i /content/drive/MyDrive/sesler/mutluerdem.m4a audio.wav #m4a dosyasını wava çevirme\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XxeBiofHHeU"
      },
      "source": [
        "import joblib\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "\n",
        "x,sr = librosa.load('/content/drive/MyDrive/sesler/kopek (1).m4a')\n",
        "print(\"x type:\",type(x),\"sr type\",type(sr))\n",
        "print(x.shape,sr)\n",
        "mfccs=librosa.feature.mfcc(y=x, sr=sr, n_mfcc=40)\n",
        "mfccs_processed = np.mean(mfccs.T,axis=0)\n",
        "result = np.array(mfccs_processed)\n",
        "mfkkk = pd.DataFrame(result)\n",
        "mfkkk = mfkkk.transpose()\n",
        "\n",
        "x_deneme = scaler.transform(mfkkk)\n",
        "print(x_deneme)\n",
        "\n",
        "#model = pickle.load(open('xgboost1.pkl', \"rb\"))\n",
        "print(\"--------------------------model_decisionregress-------------------------\")\n",
        "\n",
        "model = joblib.load('/content/drive/MyDrive/model_decisionregress.pkl')\n",
        "\n",
        "tahmin = model.predict(x_deneme)\n",
        "print(\"tahmin\" , tahmin)\n",
        "\n",
        "print(\"--------------------------svmlineer-------------------------\")\n",
        "\n",
        "model = joblib.load('/content/drive/MyDrive/svmlineer.pkl')\n",
        "\n",
        "tahmin = model.predict(x_deneme)\n",
        "guven = model.predict_proba(x_deneme)\n",
        "print(\"guven degeleri : \" , guven)\n",
        "print(\"tahmin\" , tahmin)\n",
        "\n",
        "print(\"--------------------------knn-------------------------\")\n",
        "\n",
        "model = joblib.load('/content/drive/MyDrive/knn.pkl')\n",
        "\n",
        "tahmin = model.predict(x_deneme)\n",
        "guven = model.predict_proba(x_deneme)\n",
        "print(\"guven degeleri : \" , guven)\n",
        "print(\"tahmin\" , tahmin)\n",
        "\n",
        "print(\"--------------------------model_decisionregress-------------------------\")\n",
        "\n",
        "model = joblib.load('/content/drive/MyDrive/model_decisionregress.pkl')\n",
        "\n",
        "tahmin = model.predict(x_deneme)\n",
        "print(\"guven degeleri : \" , guven)\n",
        "print(\"tahmin\" , tahmin)\n",
        "\n",
        "print(\"--------------------------model_logisticreg-------------------------\")\n",
        "\n",
        "model = joblib.load('/content/drive/MyDrive/model_logisticreg.pkl')\n",
        "\n",
        "tahmin = model.predict(x_deneme)\n",
        "guven = model.predict_proba(x_deneme)\n",
        "print(\"guven degeleri : \" , guven)\n",
        "print(\"tahmin\" , tahmin)\n",
        "\n",
        "\n",
        "print(\"--------------------------RBF-------------------------\")\n",
        "model = joblib.load('/content/drive/MyDrive/model_rbf.pkl')\n",
        "\n",
        "tahmin = model.predict(x_deneme)\n",
        "guven = model.predict_proba(x_deneme)\n",
        "print(\"guven degeleri : \" , guven)\n",
        "print(\"tahmin\" , tahmin)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zqm63sJULW2"
      },
      "source": [
        "dataFrame= dataFrame.replace(to_replace =\"human2\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"human\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"oksurme\",value =2)\n",
        "dataFrame= dataFrame.replace(to_replace =\"nefes\",value =3)\n",
        "dataFrame= dataFrame.replace(to_replace =\"ciglik\",value =4)\n",
        "dataFrame= dataFrame.replace(to_replace =\"dogs\",value =5)\n",
        "dataFrame= dataFrame.replace(to_replace =\"cats\",value =5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LZ3TiadQZwB"
      },
      "source": [
        "dectree = [\"0\", 1, \"2\", \"3\", \"4\", \"6\", \"7\", \"8\", \"9\", \"15\", \"16\", \"17\", \"18\", \"21\", \"23\", \"24\", \"34\", \"40\", \"47\", \"53\", \"57\", \"62\", \"65\", \"66\", \"72\", \"73\", \"80\", \"83\", \"84\", \"90\", \"94\", \"96\", \"99\", \"101\", \"104\", \"105\", \"112\", \"115\", \"121\", \"123\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j4SmvQ7bJwM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqXSM-ksU91b"
      },
      "source": [
        "svmss = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 53, 54, 56, 58, 59, 60, 62, 63, 65, 67, 69, 73, 74, 76, 81, 84, 85, 86, 89, 92, 93, 98, 101, 102, 106, 108, 110, 111, 114, 116, 118, 120, 122, 124, 127]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT5O18n7iWGy"
      },
      "source": [
        "import joblib\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "\n",
        "x,sr = librosa.load('/content/drive/MyDrive/Dataguncel/oksurme/0DYI_6_11_1_45_0_0_0.wav')\n",
        "print(\"x type:\",type(x),\"sr type\",type(sr))\n",
        "print(x.shape,sr)\n",
        "mfccs=librosa.feature.mfcc(y=x, sr=sr, n_mfcc=200)\n",
        "mfccs_processed = np.mean(mfccs.T,axis=0)\n",
        "result = np.array(mfccs_processed)\n",
        "mfkkk = pd.DataFrame(result)\n",
        "mfkkk = mfkkk.transpose()\n",
        "mfkkk.to_csv(\"7li.csv\")\n",
        "x_deneme =pd.read_csv(\"7li.csv\")\n",
        "\n",
        "\n",
        "\n",
        "mfkkk = mfkkk.loc[:,:]\n",
        "x_deneme = scaler.transform(mfkkk)\n",
        "model = joblib.load('/content/drive/MyDrive/pkl/insan/svmlineer.pkl')\n",
        "\n",
        "tahmin = model.predict(x_deneme)\n",
        "guven = model.predict_proba(x_deneme)\n",
        "print(\"guven degeleri : \" , guven)\n",
        "print(\"tahmin\" , tahmin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZV0vMOAb6RM"
      },
      "source": [
        "print(x_deneme)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEYprwe5Qh5F"
      },
      "source": [
        "mfkkk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBHVNNpDQkwq"
      },
      "source": [
        "mfkkk = mfkkk.loc[:,dectree]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZzCjJ_UifUN"
      },
      "source": [
        "dataFrame= dataFrame.replace(to_replace =\"human2\",value =1)\n",
        "#dataFrame= dataFrame.replace(to_replace =\"human\",value =1)\n",
        "dataFrame= dataFrame.replace(to_replace =\"oksurme\",value =2)\n",
        "dataFrame= dataFrame.replace(to_replace =\"nefes\",value =3)\n",
        "dataFrame= dataFrame.replace(to_replace =\"ciglik\",value =4)\n",
        "dataFrame= dataFrame.replace(to_replace =\"dogs\",value =5)\n",
        "dataFrame= dataFrame.replace(to_replace =\"cats\",value =5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZVhFpU5IpQD"
      },
      "source": [
        "mfkkk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiGE3yPSIjOD"
      },
      "source": [
        "x_deneme"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTeFJ34IzTvV"
      },
      "source": [
        "\"kedi\",value =1\n",
        "\"kopek\",value =2\n",
        "\"insanciglik\",value =3\n",
        "\"insankonusma\",value =4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT9ptsNvxPkP"
      },
      "source": [
        "dataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n25TJYPWxsZH"
      },
      "source": [
        "Deneme = pd.read_csv(\"ses.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O39GHF-DyJ2_"
      },
      "source": [
        "Deneme"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcgseSzgIJuz"
      },
      "source": [
        "3.33333406e-14"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}